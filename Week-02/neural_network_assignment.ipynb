{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 598,
      "metadata": {
        "id": "xCIXU44JHJvy"
      },
      "outputs": [],
      "source": [
        "# The other approach i did using keras is also giving me 77.777% acc\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense,Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = image_dataset_from_directory('homer_bart',image_size=(64, 64), label_mode = \"binary\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98LnFXbQJp6O",
        "outputId": "0c55d140-2725-4e4d-d917-234980f0500a"
      },
      "execution_count": 599,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 269 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = dataset.take(8)\n",
        "test_data = dataset.skip(8)\n",
        "train_data = train_data.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "test_data = test_data.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "jI1TVD0GMw4a"
      },
      "execution_count": 600,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess = Sequential(\n",
        "    [tf.keras.layers.Rescaling(scale=1./255)]\n",
        ")\n",
        "model = Sequential([\n",
        "    Input((64,64,3)),\n",
        "    Flatten(),\n",
        "    preprocess,\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "VJLCGUwQM-bJ"
      },
      "execution_count": 601,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_data, epochs = 30, batch_size=32, validation_data=test_data)\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(test_data)\n",
        "print(f\"Test Loss: {test_loss}, Test Accuracy: {100 * test_accuracy}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajqEcjxQNaZf",
        "outputId": "3cf3e2f6-67ff-42da-e348-1d0ff7d27262"
      },
      "execution_count": 602,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "8/8 [==============================] - 2s 79ms/step - loss: 2.2296 - accuracy: 0.4961 - val_loss: 0.9818 - val_accuracy: 0.6154\n",
            "Epoch 2/30\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.8641 - accuracy: 0.5625 - val_loss: 0.5058 - val_accuracy: 0.6154\n",
            "Epoch 3/30\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 0.6283 - accuracy: 0.6523 - val_loss: 0.4613 - val_accuracy: 0.8462\n",
            "Epoch 4/30\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.6579 - accuracy: 0.6016 - val_loss: 0.3396 - val_accuracy: 0.8462\n",
            "Epoch 5/30\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.5365 - accuracy: 0.7031 - val_loss: 0.4157 - val_accuracy: 0.7692\n",
            "Epoch 6/30\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.5709 - accuracy: 0.7383 - val_loss: 0.4476 - val_accuracy: 0.7692\n",
            "Epoch 7/30\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.5259 - accuracy: 0.7188 - val_loss: 0.4388 - val_accuracy: 0.7692\n",
            "Epoch 8/30\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.4625 - accuracy: 0.7383 - val_loss: 0.2218 - val_accuracy: 0.9231\n",
            "Epoch 9/30\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.4295 - accuracy: 0.8164 - val_loss: 0.2206 - val_accuracy: 0.9231\n",
            "Epoch 10/30\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.4637 - accuracy: 0.7695 - val_loss: 0.2466 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.4161 - accuracy: 0.7891 - val_loss: 0.2536 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.3683 - accuracy: 0.8594 - val_loss: 0.1942 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3277 - accuracy: 0.8398 - val_loss: 0.1980 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.3345 - accuracy: 0.8867 - val_loss: 0.1757 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.3101 - accuracy: 0.8711 - val_loss: 0.1853 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.2839 - accuracy: 0.9023 - val_loss: 0.1570 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.2838 - accuracy: 0.8906 - val_loss: 0.1781 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.2602 - accuracy: 0.9102 - val_loss: 0.1575 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.2307 - accuracy: 0.9336 - val_loss: 0.1437 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.2231 - accuracy: 0.9336 - val_loss: 0.1279 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.2176 - accuracy: 0.9336 - val_loss: 0.1227 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.1738 - accuracy: 0.9688 - val_loss: 0.1318 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.1540 - accuracy: 0.9727 - val_loss: 0.1069 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.1442 - accuracy: 0.9766 - val_loss: 0.1095 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.1298 - accuracy: 0.9766 - val_loss: 0.0771 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.1238 - accuracy: 0.9883 - val_loss: 0.0626 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.1088 - accuracy: 0.9883 - val_loss: 0.0690 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.1003 - accuracy: 0.9922 - val_loss: 0.0641 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0789 - accuracy: 0.9961 - val_loss: 0.0561 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0725 - accuracy: 0.9961 - val_loss: 0.0437 - val_accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0437 - accuracy: 1.0000\n",
            "Test Loss: 0.043738897889852524, Test Accuracy: 100.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #I did the same assignment with pytorch but the accuracy is always 77.777777%\n",
        "\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.optim as optim\n",
        "# from torch.utils.data import Dataset, DataLoader, random_split\n",
        "# from torchvision import transforms, datasets\n",
        "# from PIL import Image\n",
        "# import os\n",
        "\n",
        "# torch.manual_seed(42)"
      ],
      "metadata": {
        "id": "Mmnnw_dETFX3"
      },
      "execution_count": 603,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class BartHomerDataset(Dataset):\n",
        "#   def __init__(self, directory, transform=None):\n",
        "#     self.directory = directory\n",
        "#     self.transform = transform\n",
        "#     self.images = []\n",
        "#     self.labels = []\n",
        "\n",
        "#     for label, name in enumerate(['bart', 'homer']):\n",
        "#       name_dir = os.path.join(directory, name)\n",
        "#       for img_name in os.listdir(name_dir):\n",
        "#         self.images.append(os.path.join(name_dir, img_name))\n",
        "#         self.labels.append(label)\n",
        "\n",
        "#   def __len__(self):\n",
        "#     return len(self.images)\n",
        "\n",
        "#   def __getitem__(self, idx):\n",
        "#     img_path = self.images[idx]\n",
        "#     img = Image.open(img_path).convert('RGB')\n",
        "#     label = self.labels[idx]\n",
        "\n",
        "#     if self.transform:\n",
        "#       img = self.transform(img)\n",
        "\n",
        "#     return img, label"
      ],
      "metadata": {
        "id": "xL8a1Y9gYyZ_"
      },
      "execution_count": 604,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transform = transforms.Compose([\n",
        "#     transforms.Resize((64, 64)),\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5])\n",
        "# ])"
      ],
      "metadata": {
        "id": "wQFx3AGLbWXd"
      },
      "execution_count": 605,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset = BartHomerDataset(directory = 'homer_bart', transform=transform)\n",
        "\n",
        "# train_size = int(0.9 * len(dataset))\n",
        "# test_size = len(dataset) - train_size\n",
        "# train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "# train_loader = DataLoader(train_dataset, batch_size = 32, shuffle=True)\n",
        "# test_loader = DataLoader(test_dataset, batch_size = 32, shuffle=False)"
      ],
      "metadata": {
        "id": "T16Golcab2u_"
      },
      "execution_count": 606,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class BartHomerClassifier(nn.Module):\n",
        "#   def __init__(self):\n",
        "#     super(BartHomerClassifier, self).__init__()\n",
        "#     self.flatten = nn.Flatten()\n",
        "#     self.fc1 = nn.Linear(64 * 64 * 3, 128)\n",
        "#     self.fc2 = nn.Linear(128, 64)\n",
        "#     self.fc3 = nn.Linear(64, 32)\n",
        "#     self.fc4 = nn.Linear(32, 1)\n",
        "#     self.relu = nn.ReLU()\n",
        "#     self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "#   def forward(self, x):\n",
        "#     x = self.flatten(x)\n",
        "#     x = self.relu(self.fc1(x))\n",
        "#     x = self.relu(self.fc2(x))\n",
        "#     x = self.relu(self.fc3(x))\n",
        "#     x = self.sigmoid(self.fc4(x))\n",
        "#     return x\n",
        "\n",
        "#   def printAccuracy(self, loader):\n",
        "#     correct = 0\n",
        "#     total = 0\n",
        "#     with torch.no_grad():\n",
        "#       for images, labels in loader:\n",
        "#         labels = labels.float().unsqueeze(1)\n",
        "#         outputs = self.forward(images)\n",
        "#         predicted = (outputs.data > 0.5).float()\n",
        "#         total += labels.size(0)\n",
        "#         correct += (predicted == labels).sum().item()\n",
        "#     print(f\"Accuracy: {100 * correct / total}%\")\n",
        "\n",
        "# model = BartHomerClassifier()"
      ],
      "metadata": {
        "id": "Zc7iVw4oc5E6"
      },
      "execution_count": 607,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loss_fn = nn.BCELoss()\n",
        "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# num_epochs = 20\n",
        "\n",
        "# for epoch in range(num_epochs):\n",
        "#   model.train()\n",
        "#   current_loss = 0.0\n",
        "#   for images, labels in train_loader:\n",
        "#     labels = labels.float().unsqueeze(1)\n",
        "\n",
        "#     optimizer.zero_grad()\n",
        "#     outputs = model(images)\n",
        "#     loss = loss_fn(outputs, labels)\n",
        "\n",
        "#     loss.backward()\n",
        "#     optimizer.step()\n",
        "#     current_loss += loss.item()\n",
        "\n",
        "#   print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {current_loss/len(train_loader)}\")"
      ],
      "metadata": {
        "id": "UJ92Ml86dSf0"
      },
      "execution_count": 608,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.eval()\n",
        "# model.printAccuracy(test_loader)"
      ],
      "metadata": {
        "id": "KQe16c8ldw0J"
      },
      "execution_count": 609,
      "outputs": []
    }
  ]
}